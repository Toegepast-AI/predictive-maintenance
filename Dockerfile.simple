# Simple single-stage Dockerfile to avoid disk space issues
FROM python:3.11-slim-bullseye

# Install essential packages
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create non-root user
RUN useradd --create-home --shell /bin/bash --uid 1000 app

# Set working directory
WORKDIR /app

# Copy requirements and install packages
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip setuptools wheel && \
    pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY --chown=app:app app.py .

# Create cache directory for models
RUN mkdir -p /home/app/.cache && chown -R app:app /home/app/.cache
ENV HF_HOME=/home/app/.cache

# Switch to non-root user
USER app

# Pre-download model (this happens during build, not runtime)
RUN python -c "import os; os.environ['HF_HOME'] = '/home/app/.cache'; \
    from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation; \
    MODEL_NAME = 'nvidia/segformer-b0-finetuned-ade-512-512'; \
    print('Downloading model...'); \
    SegformerFeatureExtractor.from_pretrained(MODEL_NAME); \
    SegformerForSemanticSegmentation.from_pretrained(MODEL_NAME); \
    print('Model cached successfully!')"

# Expose port
EXPOSE 5000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:5000/health || exit 1

# Use gunicorn for production with optimized settings for AI workloads
CMD ["gunicorn", \
     "--bind", "0.0.0.0:5000", \
     "--workers", "1", \
     "--timeout", "300", \
     "--max-requests", "100", \
     "--max-requests-jitter", "10", \
     "--preload", \
     "--access-logfile", "-", \
     "--error-logfile", "-", \
     "app:app"]
